{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor\n",
    "\n",
    "* 파이토치(PyTorch)에서 텐서(Tensor)는 다차원 배열을 나타내는 자료형\n",
    "* numpy ndarray와 유사한 API를 제공하며 GPU를 이용한 연산도 지원\n",
    "\n",
    "```python\n",
    "# tensor 메서드를 통해 파이썬 리스트나 넘파이 배열을 PyTorch 텐서로 변환\n",
    "torch.tensor(data, dtype=None, device=None, requires_grad=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = [[1,2,3], [4,5,6]]\n",
    "x = torch.tensor(data, dtype = torch.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "tensor([[0.9316, 0.1031, 0.4544],\n",
      "        [0.2993, 0.4551, 0.4930],\n",
      "        [0.7367, 0.7023, 0.2112]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1차원 텐서 생성\n",
    "\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x)\n",
    "\n",
    "# 2차원 텐서 생성\n",
    "\n",
    "y = torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(y)\n",
    "\n",
    "# 모든 원소가 0인 3차원 텐서 생성\n",
    "\n",
    "z = torch.zeros((2,3,4))\n",
    "print(z)\n",
    "\n",
    "# 모든 원소가 1인 4차원 텐서 생성\n",
    "\n",
    "w = torch.ones((2,2,2,2))\n",
    "\n",
    "# 랜덤한 값으로 채워진 3*3 텐서 생성\n",
    "\n",
    "r = torch.rand((3,3))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5247, 0.1806, 0.5526],\n",
      "        [0.2684, 0.9905, 0.8883]])\n",
      "tensor([[ 0.2648, -1.0154,  1.9035],\n",
      "        [-1.2404, -0.1859, -0.0952]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# uniform(0,1)\n",
    "x = torch.rand((2,3))\n",
    "print(x)\n",
    "\n",
    "# normal(0, 1)\n",
    "y = torch.randn((2,3))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# .Tensor => FloatTensor\n",
    "\n",
    "a = torch.Tensor([1,2,3])\n",
    "print(a)\n",
    "\n",
    "# .empty 예제\n",
    "b = torch.empty(2,3)\n",
    "print(b)\n",
    "\n",
    "# .Tensor\n",
    "c = torch.Tensor(2,3)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .from_numpy()와 .tensor()의 차이\n",
    "\n",
    "* torch.from_numpy()는 NumPy 배열을 PyTorch Tensor로 변환, 값을 공유함\n",
    "* torch.tensor() 함수는 NumPy 배열과 유사한 새로운 PyTorch Tensor를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "tensor([1, 2, 3])\n",
      "[-1  2  3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a_np = np.array([1,2,3])\n",
    "print(a_np)\n",
    "\n",
    "# NumPy배열을 PyTorch Tensor로 변환\n",
    "a_tensor = torch.from_numpy(a_np)\n",
    "print(a_tensor)\n",
    "\n",
    "# Tensor 수정후 numpy 배열 확인\n",
    "a_tensor[0] = -1\n",
    "print(a_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "tensor([1, 2, 3])\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a_np = np.array([1,2,3])\n",
    "print(a_np)\n",
    "\n",
    "# NumPy배열을 PyTorch Tensor로 변환\n",
    "a_tensor = torch.tensor(a_np)\n",
    "print(a_tensor)\n",
    "\n",
    "# Tensor 수정후 numpy 배열 확인\n",
    "a_tensor[0] = -1\n",
    "print(a_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 속성\n",
    "\n",
    "* 데이터 타입(dtype)\n",
    "* 디바이스(device)\n",
    "* 크기(size)\n",
    "* 모양(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "3\n",
      "torch.Size([3, 2]) torch.Size([3, 2])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 데이터 타입\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x.dtype)\n",
    "\n",
    "# 디바이스\n",
    "device = torch.device('cpu')\n",
    "x = torch.tensor([1,2,3], device=device)\n",
    "print(x.device)\n",
    "\n",
    "# 크기\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x.numel())\n",
    "\n",
    "# 모양\n",
    "x = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "print(x.shape, x.size())\n",
    "\n",
    "# 모양 변경\n",
    "x = torch.Tensor([1,2,3,4])\n",
    "y = x.view(2,2) # x.reshape(2,2)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "tensor([[-4, -4],\n",
      "        [-4, -4]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor(11)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 생성\n",
    "\n",
    "a = torch.tensor([[1,2], [3,4]])\n",
    "b = torch.tensor([[5,6], [7,8]])\n",
    "\n",
    "# 덧셈\n",
    "c = a + b\n",
    "print(c)\n",
    "\n",
    "# 뺄셈\n",
    "d = a - b\n",
    "print(d)\n",
    "\n",
    "# 곱셈\n",
    "e = a * b\n",
    "print(e)\n",
    "\n",
    "# 나눗셈\n",
    "f = a/b\n",
    "print(f)\n",
    "\n",
    "# 행렬곱\n",
    "g = torch.mm(a,b)\n",
    "print(g)\n",
    "\n",
    "# 점곱\n",
    "# h = torch.dot(a, b) 2차원 점곱은 안되는 듯?\n",
    "h = torch.dot(torch.tensor([1,2]), torch.tensor([3,4]))\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor(3)\n",
      "tensor([4, 6])\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 요소별 최대값 계산\n",
    "\n",
    "i = torch.tensor([[1,2], [3,4]])\n",
    "j = torch.tensor([[4,3], [2,1]])\n",
    "k = torch.max(i, j) # 당연히 차원이 동일해야함\n",
    "print(k)\n",
    "print(torch.argmax(i)) # 토치 텐서는 첫번째 요소가 0 부터 시작\n",
    "\n",
    "# 차원 축소\n",
    "l = torch.tensor([[1,2],[3,4]])\n",
    "m = torch.sum(l, dim=0)\n",
    "print(m)\n",
    "\n",
    "# 전치\n",
    "n = torch.tensor([[1,2],[3,4]])\n",
    "o = torch.transpose(n, 0, 1) #0번째 차원과 1번째 차원을 변경\n",
    "print(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor([[1, 2],\n",
      "        [4, 5],\n",
      "        [7, 8]])\n",
      "tensor([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 인덱싱\n",
    "p = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "q = p[1, 0]\n",
    "print(q)\n",
    "\n",
    "# 슬라이싱\n",
    "r = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "s = r[:, :2]\n",
    "print(s)\n",
    "\n",
    "# 조건부 인덱싱\n",
    "t = torch.tensor([1, 2, 3, 4, 5])\n",
    "u = t[t > 3]\n",
    "print(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) torch.Size([4])\n",
      "tensor([[1, 2, 3, 4]]) torch.Size([1, 4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]]) torch.Size([4, 1])\n",
      "tensor([1, 2, 3, 4]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1,2,3,4])\n",
    "print(x, x.shape)\n",
    "\n",
    "# 텐서 차원 변경\n",
    "y = x.unsqueeze(0)\n",
    "print(y, y.shape)\n",
    "\n",
    "y = x.unsqueeze(1)\n",
    "print(y, y.shape)\n",
    "\n",
    "y = x.squeeze()\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([1, 2, 3]) tensor([2, 1, 0])\n",
      "tensor([4, 5, 6]) tensor([0, 1, 2])\n",
      "tensor([3, 2, 1]) tensor([2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1,2,3,4])\n",
    "\n",
    "# 텐서 reshape\n",
    "y = x.reshape(2, 2) #x.view와 동일\n",
    "print(y)\n",
    "\n",
    "# 텐서 정렬\n",
    "x = torch.tensor([3, 2, 1])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "z = torch.tensor([1, 2, 3])\n",
    "a, b = torch.sort(x)\n",
    "print(a, b)\n",
    "\n",
    "a, b = torch.sort(y)\n",
    "print(a, b)\n",
    "\n",
    "a, b = torch.sort(z, descending=True)\n",
    "print(a, b)\n",
    "# torch.sort는 두개의 결과를 만듬 => sort된 결과, 바뀌기 전 값의 위치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 병합\n",
    "\n",
    "* 병합하는 방식 역시 numpy와 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 5 6]\n",
      " [3 4 7 8]]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "[[1 2 5 6]\n",
      " [3 4 7 8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr1 = np.array([[1, 2], [3, 4]])\n",
    "arr2 = np.array([[5, 6], [7, 8]])\n",
    "print(np.concatenate((arr1, arr2), axis=1))\n",
    "print(np.vstack((arr1, arr2)))\n",
    "print(np.hstack((arr1, arr2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a1 = torch.tensor(arr1)\n",
    "a2 = torch.tensor(arr2)\n",
    "print(torch.cat((a1, a2), axis=1))\n",
    "print(torch.vstack((a1, a2)))\n",
    "print(torch.hstack((a1, a2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유용한 함수들\n",
    "\n",
    "* torch.eq : 두개의 같은 형태의 텐서를 입력 받아 두 텐서 원소 간의 동등성을 비교하여 불린 형태로 반환\n",
    "* torch.softmax : 입력값을 확률 형태로 변환해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True])\n",
      "tensor([ True,  True, False])\n"
     ]
    }
   ],
   "source": [
    "# torch.eq\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([1,2,3])\n",
    "c = torch.tensor([1,2,4])\n",
    "\n",
    "res1 = torch.eq(a, b)\n",
    "res2 = torch.eq(a, c)\n",
    "\n",
    "print(res1)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "# torch.softmax\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([1.0, 2.0, 3.0]) # 정수형은 오류 발생\n",
    "res = torch.softmax(a, dim=0)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인플레이스 연산\n",
    "\n",
    "인플레이스 연산은 다음과 같이 _가 연산자 뒤에 붙는 메소드를 사용하여 수행할 수 있습니다.\n",
    "  \n",
    "* add_\n",
    "* sub_\n",
    "* mul_\n",
    "* div_\n",
    "* pow_\n",
    "* sqrt_\n",
    "* round_\n",
    "* floor_\n",
    "* ceil_\n",
    "* clamp_\n",
    "* fill_\n",
    "\n",
    "주의점 : 인플레이스 연산을 사용하면 원본 데이터가 변경됨, 복사본이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.zeros(3,3)\n",
    "\n",
    "y = x.fill_(1)\n",
    "print(x, y) # 원본 데이터 x가 변경된걸 확인할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 5, 5],\n",
      "        [5, 5, 5],\n",
      "        [5, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.full((3,3), 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset과 DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        \"\"\"\n",
    "        커스텀 이미지 데이터셋 클래스의 생성자입니다.\n",
    "\n",
    "        Args:\n",
    "            file_paths (list): 이미지 파일 경로의 리스트\n",
    "            labels (list): 이미지 레이블의 리스트\n",
    "            transform (callable, optional): 이미지에 적용할 전처리 함수\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        데이터셋의 전체 샘플 개수를 반환합니다.\n",
    "        \"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        인덱스에 해당하는 샘플을 가져옵니다.\n",
    "\n",
    "        Args:\n",
    "            idx (int): 샘플의 인덱스\n",
    "\n",
    "        Returns:\n",
    "            image (torch.Tensor): 이미지 데이터의 텐서\n",
    "            label (torch.Tensor): 이미지 레이블의 텐서\n",
    "        \"\"\"\n",
    "        # 이미지 파일을 불러옴\n",
    "        image = Image.open(self.file_paths[idx])\n",
    "\n",
    "        # 이미지에 전처리 함수를 적용 (예: Resize, RandomCrop, ToTensor 등)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # 이미지 레이블을 텐서로 변환\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset과 transforms\n",
    "\n",
    "* torchvivsion.transforms을 사용하여 이미지 전처리 작업을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "img_T = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, ), (0.5, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든 Transformer을 CustomImageDataset 클래스에 적용\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, file_list, label_list, img_T = None):\n",
    "        self.file_list = file_list\n",
    "        self.label_list = label_list\n",
    "        self.img_T = img_T\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.file_list[idx])\n",
    "        label = self.label_list[idx]\n",
    "        \n",
    "        if self.img_T is not None:\n",
    "            image = self.img_T(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len((self.file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomImageDataset 클래스 인스턴스 생성\n",
    "\n",
    "# dataset = CustomImageDataset(file_list, label_list, img_T=img_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.transforms\n",
    "\n",
    "파이토치에서 이미지 데이터의 전처리 및 데이터 증강을 위해 제공하는 모듈\n",
    "\n",
    "* Resize: 이미지의 크기를 조절합니다.\n",
    "* RandomResizedCrop: 이미지를 무작위로 자르고 크기를 조절합니다.\n",
    "* RandomHorizontalFlip: 이미지를 무작위로 수평으로 뒤집습니다.\n",
    "* RandomVerticalFlip: 이미지를 무작위로 수직으로 뒤집습니다.\n",
    "* ToTensor: 이미지를 텐서로 변환합니다.\n",
    "* Normalize: 이미지를 정규화합니다.\n",
    "* ColorJitter: 이미지의 색상을 무작위로 조정합니다.\n",
    "* RandomRotation: 이미지를 무작위로 회전합니다.\n",
    "* RandomCrop: 이미지를 무작위로 자릅니다.\n",
    "* Grayscale: 이미지를 흑백으로 변환합니다.\n",
    "* RandomSizedCrop: 이미지를 무작위로 자르고 크기를 조절합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# 이미지 전처리 작업을 정의\n",
    "preprocess = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5), (0.5))# T.Normalize([0.5],[0.5])\n",
    "])\n",
    "\n",
    "# 이미지에 전처리 작업 적용\n",
    "# image = Image.open('image.jpg')\n",
    "# imge = preprocess(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.utils.save_image\n",
    "\n",
    "이미지 텐서를 파일로 저장하는 함수\n",
    "\n",
    "```python\n",
    "torchvision.utils.save_image(tensor, filename, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)\n",
    "```\n",
    "\n",
    "* tensor : (Tensor) - 저장할 이미지 텐서. shape는 (batch_size, channels, height, width) 이어야 합니다.\n",
    "* filename : (str) - 저장할 파일의 경로와 이름입니다.\n",
    "* nrow : (int, optional) - 저장할 이미지들을 한 줄에 몇 개씩 보여줄 것인지 결정하는 인자입니다. 기본값은 8입니다.\n",
    "* padding : (int, optional) - 이미지들 사이의 간격을 몇 개의 픽셀로 할 것인지 결정하는 인자입니다. 기본값은 2입니다.\n",
    "* normalize : (bool, optional) - 이미지의 값을 [0, 1]로 정규화할 것인지 결정하는 인자입니다. 기본값은 True입니다.\n",
    "* range : (tuple, optional) - 이미지를 정규화할 때 사용할 범위를 결정하는 인자입니다. 기본값은 None으로, 입력된 텐서의 값 범위를 그대로 사용합니다.\n",
    "* scale_each : (bool, optional) - 이미지를 정규화할 때 각 이미지마다 다른 범위를 사용할지 여부를 결정하는 인자입니다. 기본값은 False입니다.\n",
    "* pad_value : (float, optional) - 이미지의 테두리를 채우는 값입니다. 기본값은 0입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예\n",
    "\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "img = torch.randn(3, 64, 64)\n",
    "\n",
    "vutils.save_image(img, 'my_image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "DataLoader는 파이토치(PyTorch)에서 제공하는 데이터 로딩 유틸리티로, 모델 학습 시에 데이터를 배치(batch) 단위로 로드하여 효율적인 학습을 가능하게 해주는 클래스입니다.\n",
    "\n",
    "* dataset: 데이터를 로드할 데이터셋 객체를 지정합니다. 이는 torch.utils.data.Dataset 클래스를 상속받은 사용자 정의 데이터셋 클래스를 사용하거나, torchvision의 내장 데이터셋 클래스를 사용할 수 있습니다. (기본값: None)\n",
    "* batch_size: 한 번에 로드할 배치(batch)의 크기를 지정합니다. 작은 배치 크기는 더 많은 메모리를 사용하지만 더 자주 모델이 업데이트되고 더 높은 학습 속도를 제공합니다. (기본값: 1)\n",
    "* shuffle: 데이터를 섞을지 여부를 지정합니다. True로 설정할 경우, 데이터가 매 에폭(epoch)마다 섞여서 모델이 각 배치에서 다양한 데이터를 학습하도록 도와줍니다.(기본값: False)\n",
    "* num_workers: 데이터 로딩에 사용할 워커(worker)의 수를 지정합니다. 병렬 처리를 통해 데이터 로딩 속도를 향상시키는 데 사용됩니다.(기본값: 0)\n",
    "* pin_memory: GPU 메모리에 데이터를 고정할지 여부를 지정합니다. GPU를 사용하는 경우 True로 설정하면 데이터가 CPU와 GPU 간에 더 빠르게 복사되어 학습 속도를 향상시킬 수 있습니다. (기본값: False)\n",
    "* collate_fn: 배치를 생성하기 전에 데이터를 결합하는 함수를 지정합니다. 기본값은 None이며, 데이터셋이 출력하는 원시 데이터의 리스트를 배치로 결합합니다. 필요에 따라 사용자 정의 결합 함수를 지정하여 배치를 구성할 수 있습니다.(기본값: None)\n",
    "* drop_last: 마지막 배치의 크기가 batch_size보다 작을 경우, 해당 배치를 무시할지 여부를 지정합니다. True로 설정할 경우 마지막 배치를 무시합니다.(기본값: False)\n",
    "\n",
    "```python\n",
    "# 사용법\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CustomImageDatset 객체 생성\n",
    "dataset = CustomImageDataset(file_list, label_list, transfrom=transform) CustomImageDatset 인스턴스 생성\n",
    "\n",
    "# DataLoader 생성\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# 데이터 로딩을 위한 반복문\n",
    "for images, labels in dataloader:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 만들기\n",
    "\n",
    "파이토치에서 모델을 만드는 방법\n",
    "* nn.Module 클래스를 상속하여 모델 클래스를 정의하는 방법\n",
    "* nn.Sequential 클래스를 사용하여 모델을 정의하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module 사용\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 모델의 레이어들을 정의하고 초기화\n",
    "        self.layer1 = nn.Linear(784, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(256, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 모델의 순전파 동작을 구현\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential 사용\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 방법을 함께 사용하여 모델 정의\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__() # MyModel이 nn.Module을 상속받도록하는 작업\n",
    "        # nn.Sequential을 사용하여 레이어들을 조합\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # nn.Sequential로 정의한 레이어들의 순전파 동작이 자동으로 수행됨\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.BatchNorm1d\n",
    "\n",
    "nn.BatchNorm1d는 PyTorch 라이브러리의 하나의 정규화(normalization) 모듈입니다.   \n",
    "특히, 인공 신경망에서 배치 정규화(batch normalization)를 수행하는 데 사용됩니다.   \n",
    "배치 정규화는 입력 데이터를 평균과 표준편차로 정규화하여, 모델이 더 잘 수렴하도록 돕는 방법 중 하나입니다.  \n",
    "\n",
    "```python \n",
    "torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "```\n",
    "\n",
    "* num_features: 입력 데이터의 크기를 지정하는 인자입니다. 반드시 지정해야 합니다.\n",
    "* eps: 분모에 더해지는 작은 값으로, 0으로 나누는 것을 방지하기 위한 인자입니다. 기본값은 1e-05입니다.\n",
    "* momentum: 이전 배치의 평균과 분산값을 얼마나 반영할지를 지정하는 인자입니다. 기본값은 0.1입니다.\n",
    "* affine: 정규화된 값을 확대 및 이동시킬지 여부를 지정하는 인자입니다. 기본값은 True입니다.\n",
    "* track_running_stats: 배치 정규화의 효과를 추적할지 여부를 지정하는 인자입니다. 기본값은 True입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.bn = nn.BatchNorm1d(num_features=50)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.BatchNorm2d\n",
    "\n",
    "nn.BatchNorm2d는 PyTorch의 배치 정규화 (Batch Normalization)을 수행하는 클래스로, 2차원 이미지 데이터에 대한 배치 정규화를 적용할 수 있습니다\n",
    "\n",
    "```python\n",
    "nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "```\n",
    "\n",
    "* num_features: 입력 채널의 개수 (정수)\n",
    "* eps: 분모에 더해지는 작은 값 (스칼라), 기본값은 1e-05\n",
    "* momentum: 배치 정규화의 이동 평균 계산 시 사용되는 모멘텀 값 (스칼라), 기본값은 0.1\n",
    "* affine: 스케일과 시프트 매개변수를 학습할지 여부 (불리언), 기본값은 True\n",
    "* track_running_stats: 배치 정규화의 통계량을 추적할지 여부 (불리언), 기본값은 True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Conv1d\n",
    "\n",
    "1차원 컨볼루션 레이어를 정의하는 클래스, 1차원 컨볼루션은 입력 데이터의 한 방향으로 컨볼루션 연산을 수행\n",
    "\n",
    "```python\n",
    "nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "```\n",
    "\n",
    "* in_channels: 입력 데이터의 채널 개수입니다. 예를 들어, 입력 데이터가 RGB 이미지인 경우 in_channels는 3이 됩니다.\n",
    "* out_channels: 출력 데이터의 채널 개수입니다. 이는 컨볼루션 필터의 개수를 의미하며, 출력 데이터가 몇 개의 특징 맵으로 변환되는지를 결정합니다.\n",
    "* kernel_size: 컨볼루션 필터(커널)의 크기입니다. 정수 또는 튜플 형태로 지정할 수 있습니다. 예를 들어, kernel_size=3은 3개의 연속된 입력 값에 대해 컨볼루션 연산을 수행하고, kernel_size=(3, 5)는 3개의 연속된 입력 값에 대해 한 방향으로 5개의 컨볼루션 연산을 수행합니다.\n",
    "* stride: 컨볼루션 필터의 이동 간격을 지정합니다. 정수 또는 튜플 형태로 지정할 수 있습니다. 예를 들어, stride=1은 한 칸씩 이동하면서 컨볼루션 연산을 수행하고, stride=2는 두 칸씩 이동하면서 컨볼루션 연산을 수행합니다.\n",
    "* padding: 입력 데이터에 대해 가상의 패딩을 추가하는 것으로, 컨볼루션 연산의 경계 효과를 조절합니다. 정수 또는 튜플 형태로 지정할 수 있습니다. 예를 들어, padding=1은 입력 데이터에 한 칸의 패딩을 추가하고, padding=(1, 2)는 입력 데이터에 한 방향으로 한 칸의 패딩을 추가하고 다른*  방향으로 두 칸의 패딩을 추가합니다.\n",
    "* dilation: 컨볼루션 필터 내의 값 사이의 간격을 조절하여, 더 넓은 영역을 감지할 수 있도록 합니다. 정수 또는 튜플 형태로 지정할 수 있습니다.\n",
    "* groups: 입력 데이터와 출력 데이터의 채널을 그룹화하여 연산을 수행하는 것으로, 다양한 네트워크 아키텍처를 구성하는 데 사용됩니다.\n",
    "* bias: 편향(bias) 사용 여부를 결정하는 불리언 값입니다. 기본값은 True로 편향이 사용되지만, False로 설정하여 편향을 사용하지 않을 수도 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouput size:  torch.Size([16, 64, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력데이터 : (배치 크기, seq_length, window size)\n",
    "input_size = (16, 3, 32)\n",
    "\n",
    "# 1차원 컨볼루션 레이어 정의\n",
    "conv1d = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3)\n",
    "\n",
    "# 입력데이터 생성\n",
    "input_data = torch.randn(input_size)\n",
    "\n",
    "# 컨볼루션 연산 수행\n",
    "output = conv1d(input_data)\n",
    "\n",
    "# 출력 데이터의 크기 (배치크기, 출력 채널, 출력 시퀀스 길이)\n",
    "print(\"Ouput size: \", output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Conv2d\n",
    "\n",
    "nn.Conv2d는 파이토치(PyTorch)에서 제공하는 2D 컨볼루션(Convolution) 레이어 클래스입니다. 이미지나 2D 데이터의 특징 추출에 주로 사용되며, 합성곱 신경망(Convolutional Neural Network, CNN)에서 핵심적인 레이어 중 하나입니다.\n",
    "\n",
    "```python\n",
    "nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "```\n",
    "\n",
    "* in_channels (int): 입력 채널의 개수. 예를 들어, RGB 이미지의 경우 3개의 채널을 가지므로 in_channels는 3이 됩니다.\n",
    "* out_channels (int): 출력 채널의 개수, 즉 컨볼루션 필터의 개수입니다. 이 값이 클수록 더 복잡한 특징을 학습할 수 있지만, 모델의 파라미터 수가 증가하게 됩니다.\n",
    "* kernel_size (int 또는 tuple): 컨볼루션 필터의 크기. 예를 들어, 3x3 필터의 경우 kernel_size는 3 또는 (3, 3)으로 지정할 수 있습니다.\n",
    "* stride (int 또는 tuple, optional): 필터의 이동 간격, 즉 스트라이드(stride)입니다. 기본값은 1이며, 더 큰 값으로 설정하면 출력 특징 맵의 크기가 작아지게 됩니다.\n",
    "* padding (int 또는 tuple, optional): 입력 데이터의 가장자리에 추가되는 패딩의 크기입니다. 기본값은 0이며, 패딩을 사용하면 출력 특징 맵의 크기를 보존하면서 입력 데이터의 가장자리 정보를 유지할 수 있습니다.\n",
    "* dilation (int 또는 tuple, optional): 딜레이션(dilation) 레이트입니다. 딜레이션은 필터의 간격을 더 크게 두어 더 넓은 영역의 정보를 가져오는 데 사용됩니다. 기본값은 1이며, 값이 커질수록 필터의 영역이 더 넓어지게 됩니다.\n",
    "* groups (int, optional): 입력 및 출력 채널을 묶는(grouping) 개수입니다. 기본값은 1이며, 값이 크면 채널 간의 관련성을 줄이는 효과가 있습니다.\n",
    "* bias (bool, optional): 편향(bias)을 사용할지 여부를 결정하는 플래그입니다. 기본값은 True이며, False로 설정하면 편향이 사용되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([64, 64, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력 데이터의 크기: (배치 크기, 채널, 높이, 너비)\n",
    "input_size = (64, 3, 32, 32)\n",
    "\n",
    "# Conv2d 레이어 정의\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# 입력 데이터 생성\n",
    "input_data = torch.randn(input_size)\n",
    "\n",
    "# 컨볼루션 연산 수행\n",
    "output = conv(input_data)\n",
    "\n",
    "# 출력 데이터의 크기 출력\n",
    "print(\"Output size:\", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Flatten()\n",
    "\n",
    "nn.Flatten()은 PyTorch의 텐서를 1차원으로 평탄화(flatten)하는 클래스입니다. 이는 다차원 텐서를 1차원으로 변환하여 다층 퍼셉트론(MLP) 등의 신경망 레이어에 입력으로 제공할 수 있게 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 46875])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(30, 3, 25, 25) # batch_size, num_channels, height, width => 순서 매우 중요\n",
    "flatten = nn.Flatten()\n",
    "x_flatten = flatten(x)\n",
    "x_flatten.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear\n",
    "\n",
    "nn.Linear는 파이토치에서 사용되는 선형 변환(linear transformation)을 수행하는 클래스로, Fully Connected Layer 또는 Dense Layer라고도 불립니다.\n",
    "\n",
    "nn.Linear 클래스의 생성자(__init__)에는 다음과 같은 인수가 있습니다:\n",
    "\n",
    "* in_features (int): 입력 텐서의 크기. 입력 텐서의 차원(dimension) 또는 특성(feature)의 수입니다.\n",
    "* out_features (int): 출력 텐서의 크기. 출력 텐서의 차원(dimension) 또는 특성(feature)의 수입니다.\n",
    "* bias (bool, optional): 편향(bias)을 사용할지 여부를 지정합니다. 기본값은 True입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor Size:  torch.Size([1, 10])\n",
      "Output Tensor Size:  torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력 텐서의 크기가 10이고 출력 텐서의 크기가 20인 선형 변환을 수행하는 nn.Linear 모듈 생성\n",
    "linear = nn.Linear(10, 20)\n",
    "\n",
    "# 입력 텐서 생성 (크기가 10인 벡터)\n",
    "input_tensor = torch.randn(1, 10)\n",
    "\n",
    "# 선형 변환 수행 (입력 텐서를 출력 텐서로 변환)\n",
    "output_tensor = linear(input_tensor)\n",
    "\n",
    "print(\"Input Tensor Size: \", input_tensor.size())\n",
    "print(\"Output Tensor Size: \", output_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.MaxPool1d\n",
    "\n",
    "nn.MaxPool1d는 파이토치(PyTorch) 라이브러리에서 제공하는 1차원(Max Pooling) 최대 풀링 연산을 수행하는 클래스입니다. 컨볼루션 신경망에서 주로 사용  \n",
    "공간 차원을 주려 불필요한 정보를 줄이는 효과를 얻을 수 있다\n",
    "\n",
    "* kernel_size: 풀링 윈도우의 크기를 나타내는 정수 값 또는 튜플입니다. 입력 신호에서 추출할 최대값을 결정하는데 사용됩니다. 일반적으로 2 또는 3과 같은 작은 정수 값이 사용됩니다.\n",
    "* stride: 풀링 윈도우의 이동 간격을 나타내는 정수 값 또는 튜플입니다. 이 매개변수는 풀링 연산의 겹침(overlapping)을 조절하며, 일반적으로 kernel_size와 같은 값을 사용합니다.(기본값: None으로 kernel_size와 같은 값 설정됨)\n",
    "* padding: 입력 신호 주위에 추가할 패딩(padding)의 크기를 나타내는 정수 값 또는 튜플입니다. 패딩은 입력 신호의 경계 부분에서 풀링 윈도우가 넘어갈 때 발생하는 정보 손실을 줄이는 역할을 합니다. 일반적으로 0 또는 1과 같은 작은 값이 사용됩니다.(기본값: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor size: torch.Size([1, 1, 10])\n",
      "Output tensor size: torch.Size([1, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력 텐서 생성 (배치 크기: 1, 채널: 1, 시퀀스 길이: 10)\n",
    "input_tensor = torch.randn(1, 1, 10)\n",
    "\n",
    "# MaxPool1d 인스턴스 생성\n",
    "maxpool = nn.MaxPool1d(kernel_size=2, padding=0)\n",
    "\n",
    "# 최대 풀링 수행\n",
    "output_tensor = maxpool(input_tensor)\n",
    "\n",
    "# 입력 텐서와 출력 텐서의 크기 확인\n",
    "print(\"Input tensor size:\", input_tensor.size())\n",
    "print(\"Output tensor size:\", output_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.ModuleList()\n",
    "\n",
    "nn.ModuleList는 파이토치에서 사용되는 모듈들을 리스트 형태로 관리하는 클래스입니다. 이를 사용하면 동적으로 모듈들을 추가하거나 삭제할 수 있습니다.nn.ModuleList는 nn.Module을 상속한 클래스 내에서 사용됩니다.  \n",
    "nn.ModuleList는 파이토치 모델의 서브 모듈(sub-module)들을 리스트 형태로 정의하고, 해당 리스트를 모델 클래스의 속성으로 사용합니다. 이렇게 정의된 nn.ModuleList는 자동으로 모델의 파라미터들과 함께 관리되며, 모델의 forward 연산에서 호출될 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(5):\n",
    "            self.linears.append(nn.Linear(10, 20))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.linears:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.ReLU\n",
    "\n",
    "```python\n",
    "ReLU(x) = max(0, x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([-0.5263,  0.5417,  0.1646, -0.5202,  1.2844])\n",
      "after ReLU()\n",
      "x:  tensor([-0.5263,  0.5417,  0.1646, -0.5202,  1.2844])\n",
      "y:  tensor([0.0000, 0.5417, 0.1646, 0.0000, 1.2844])\n",
      "------------------------------------------------------------\n",
      "x:  tensor([-0.2418, -0.6900,  1.3554, -0.2459,  1.1599])\n",
      "after ReLU(inplace=True)\n",
      "x:  tensor([0.0000, 0.0000, 1.3554, 0.0000, 1.1599])\n",
      "y:  tensor([0.0000, 0.0000, 1.3554, 0.0000, 1.1599])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ReLU 레이어 인스턴스화\n",
    "relu = nn.ReLU()  # inplace=False가 기본값\n",
    "\n",
    "# ReLU 연산 적용\n",
    "x = torch.randn(5)\n",
    "print('x: ',x)\n",
    "y = relu(x)  # 원본 x는 수정되지 않고, 새로운 텐서 y를 반환\n",
    "print('after ReLU()')\n",
    "print('x: ',x)\n",
    "print('y: ',y)\n",
    "print('-'*60)\n",
    "\n",
    "# inplace=True로 설정한 ReLU 연산\n",
    "x = torch.randn(5)\n",
    "print('x: ',x)\n",
    "relu_inplace = nn.ReLU(inplace=True)\n",
    "y = relu_inplace(x)  # 원본 x가 직접 수정\n",
    "print('after ReLU(inplace=True)')\n",
    "print('x: ',x)\n",
    "print('y: ',y)\n",
    "\n",
    "# inplace를 쓸일이 있나 ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.LeakyReLU\n",
    "\n",
    "기본적으로 ReLU 함수와 유사하지만, 입력값이 음수일 때 기울기를 0이 아닌 작은 값으로 유지합니다. 이렇게 하면 ReLU 함수에서 발생하는 \"죽은 뉴런(dead neuron)\" 문제를 완화할 수 있습니다.\n",
    "\n",
    "```python\n",
    "torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)\n",
    "```\n",
    "\n",
    "* negative_slope: 음수 기울기 값을 지정하는 인자입니다. 기본값은 0.01입니다.\n",
    "* inplace: 연산을 직접 입력 데이터에 수행할지 여부를 지정하는 인자입니다. 기본값은 False입니다.\n",
    "\n",
    "* ex) negative_slope 가 0.01 이면 input data가 -1일때는 -0.01, input_data가 -10일때는 -0.1 이런식으로 변환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
