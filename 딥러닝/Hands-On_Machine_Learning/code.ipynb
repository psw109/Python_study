{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2부 신경망과 딥러닝\n",
    "\n",
    "p.350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 케라스를 사용한 인공 신경망 소개\n",
    "\n",
    "p.351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 케라스로 다층 퍼셉트론 구현하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 텐서플로우 설치\n",
    "\n",
    "* 설치 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 시퀀셜 API를 사용하여 이미지 분류기 만들기 \n",
    "\n",
    "* 패션 MNIST 데이터 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 스케일링\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train은 숫자 라벨, 정확한 라벨 지정이 필요\n",
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : 하이퍼 파라미터 갯수\n",
    "\n",
    "* 입력데이터가 28 * 28 사이즈\n",
    "* 은닉층이 300 사이즈\n",
    "* 가중치 300개\n",
    "* 따라서 최종 파라미터는 ```28 * 28 * 300 + 300```\n",
    "* 가중치 파라미터가 있다는걸 생각해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_11 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성, 두 개의 은닉층으로 이루어진 분류용 다층 퍼셉트론\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.layers.reshaping.flatten.Flatten at 0x28d28b210>,\n",
       " <keras.src.layers.core.dense.Dense at 0x175efc850>,\n",
       " <keras.src.layers.core.dense.Dense at 0x177b2fb90>,\n",
       " <keras.src.layers.core.dense.Dense at 0x175eff610>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_41'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00259797  0.00692805  0.02403083 ...  0.0414771  -0.01000351\n",
      "   0.0455245 ]\n",
      " [-0.00720634 -0.06696572 -0.03759375 ... -0.0569494  -0.05621594\n",
      "   0.02254874]\n",
      " [-0.06909169 -0.04825979 -0.0679223  ...  0.04206449  0.04631072\n",
      "   0.00874852]\n",
      " ...\n",
      " [ 0.03305165 -0.03757436 -0.00268551 ...  0.07410562  0.04512954\n",
      "  -0.04381103]\n",
      " [-0.04604832  0.0169794  -0.06896992 ... -0.02869607  0.06718469\n",
      "   0.02253949]\n",
      " [-0.04427429  0.06889193 -0.05900093 ... -0.04101263  0.01060172\n",
      "   0.00467125]]\n",
      "(784, 300)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights() # 첫번째 은닉층의 초기 가중치, 편향\n",
    "print(weights)\n",
    "print(weights.shape)\n",
    "print(biases)\n",
    "print(biases.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'sgd',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : sparse_categorical_crossentropy와 categorical_crossentropy의 차이점\n",
    "\n",
    "* 샘플마다 타겟 클레스가 하나 이면(예를들어 1번샘플의 정답 = 9, 2번샘플의 정답 = 3) sparse ~ 사용\n",
    "* 샘플마다 타겟 클래스가 원핫 인코딩 벡터형태면(1번 샘플의 정답 = (0,1,0,0), 2번 샘플의 정답 = (1,0,0,0)) categorical ~ 사용\n",
    "    * 원 핫 벡터 변환 함수 : keras.utils.to_categorical()\n",
    "    * 반대는 np.argmax(axis = 1)를 이용해 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer = sgd는 경사 하강법을 이용해 훈련 한다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics = ['accuracy']는 분류 문제이기 때문에 이러한 형태로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : model.fit() 메서드 \n",
    "\n",
    "* fit() 메서드는 마지막으로 실행한 파라미터 값을 기억한다, 따라서 다시 실행하게 되면 마지막에 최적화된 파라미터에서 시작함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7160 - accuracy: 0.7619 - val_loss: 0.5091 - val_accuracy: 0.8234\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4893 - accuracy: 0.8292 - val_loss: 0.4420 - val_accuracy: 0.8512\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4444 - accuracy: 0.8432 - val_loss: 0.4097 - val_accuracy: 0.8596\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4176 - accuracy: 0.8529 - val_loss: 0.3994 - val_accuracy: 0.8620\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3977 - accuracy: 0.8609 - val_loss: 0.3775 - val_accuracy: 0.8722\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3815 - accuracy: 0.8664 - val_loss: 0.3831 - val_accuracy: 0.8646\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3679 - accuracy: 0.8687 - val_loss: 0.3601 - val_accuracy: 0.8722\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3567 - accuracy: 0.8729 - val_loss: 0.3522 - val_accuracy: 0.8776\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3459 - accuracy: 0.8759 - val_loss: 0.3501 - val_accuracy: 0.8728\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.8797 - val_loss: 0.3497 - val_accuracy: 0.8768\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3272 - accuracy: 0.8836 - val_loss: 0.3431 - val_accuracy: 0.8780\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3195 - accuracy: 0.8853 - val_loss: 0.3395 - val_accuracy: 0.8806\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3123 - accuracy: 0.8888 - val_loss: 0.3403 - val_accuracy: 0.8794\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3053 - accuracy: 0.8900 - val_loss: 0.3302 - val_accuracy: 0.8824\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2986 - accuracy: 0.8918 - val_loss: 0.3277 - val_accuracy: 0.8832\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2935 - accuracy: 0.8935 - val_loss: 0.3149 - val_accuracy: 0.8844\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2859 - accuracy: 0.8963 - val_loss: 0.3151 - val_accuracy: 0.8864\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2809 - accuracy: 0.8992 - val_loss: 0.3157 - val_accuracy: 0.8848\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2753 - accuracy: 0.9006 - val_loss: 0.3138 - val_accuracy: 0.8850\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2703 - accuracy: 0.9022 - val_loss: 0.3089 - val_accuracy: 0.8876\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2651 - accuracy: 0.9037 - val_loss: 0.3184 - val_accuracy: 0.8846\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2622 - accuracy: 0.9047 - val_loss: 0.3180 - val_accuracy: 0.8870\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2571 - accuracy: 0.9077 - val_loss: 0.3265 - val_accuracy: 0.8860\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2523 - accuracy: 0.9089 - val_loss: 0.3014 - val_accuracy: 0.8926\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2480 - accuracy: 0.9103 - val_loss: 0.3128 - val_accuracy: 0.8860\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2448 - accuracy: 0.9116 - val_loss: 0.2942 - val_accuracy: 0.8934\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2396 - accuracy: 0.9139 - val_loss: 0.3187 - val_accuracy: 0.8788\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2368 - accuracy: 0.9147 - val_loss: 0.2946 - val_accuracy: 0.8942\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2314 - accuracy: 0.9162 - val_loss: 0.3008 - val_accuracy: 0.8918\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2286 - accuracy: 0.9176 - val_loss: 0.2961 - val_accuracy: 0.8948\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련과 평가\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 분포가 편중되어있다면 fit()메서드를 호출할때 class_weight 매개변수를 지정할 수 잇다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.715961</td>\n",
       "      <td>0.761873</td>\n",
       "      <td>0.509121</td>\n",
       "      <td>0.8234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.489252</td>\n",
       "      <td>0.829236</td>\n",
       "      <td>0.441950</td>\n",
       "      <td>0.8512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444401</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.409725</td>\n",
       "      <td>0.8596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.417573</td>\n",
       "      <td>0.852909</td>\n",
       "      <td>0.399407</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.397692</td>\n",
       "      <td>0.860891</td>\n",
       "      <td>0.377473</td>\n",
       "      <td>0.8722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.381477</td>\n",
       "      <td>0.866400</td>\n",
       "      <td>0.383061</td>\n",
       "      <td>0.8646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.367873</td>\n",
       "      <td>0.868709</td>\n",
       "      <td>0.360080</td>\n",
       "      <td>0.8722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.356671</td>\n",
       "      <td>0.872909</td>\n",
       "      <td>0.352227</td>\n",
       "      <td>0.8776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.345943</td>\n",
       "      <td>0.875927</td>\n",
       "      <td>0.350135</td>\n",
       "      <td>0.8728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.335326</td>\n",
       "      <td>0.879745</td>\n",
       "      <td>0.349719</td>\n",
       "      <td>0.8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.327220</td>\n",
       "      <td>0.883600</td>\n",
       "      <td>0.343063</td>\n",
       "      <td>0.8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.319549</td>\n",
       "      <td>0.885345</td>\n",
       "      <td>0.339544</td>\n",
       "      <td>0.8806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.312339</td>\n",
       "      <td>0.888782</td>\n",
       "      <td>0.340266</td>\n",
       "      <td>0.8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.305344</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.330250</td>\n",
       "      <td>0.8824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.298564</td>\n",
       "      <td>0.891836</td>\n",
       "      <td>0.327683</td>\n",
       "      <td>0.8832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.293506</td>\n",
       "      <td>0.893545</td>\n",
       "      <td>0.314891</td>\n",
       "      <td>0.8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.285950</td>\n",
       "      <td>0.896309</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.8864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.280920</td>\n",
       "      <td>0.899236</td>\n",
       "      <td>0.315711</td>\n",
       "      <td>0.8848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.275325</td>\n",
       "      <td>0.900582</td>\n",
       "      <td>0.313819</td>\n",
       "      <td>0.8850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.270304</td>\n",
       "      <td>0.902182</td>\n",
       "      <td>0.308889</td>\n",
       "      <td>0.8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.265079</td>\n",
       "      <td>0.903691</td>\n",
       "      <td>0.318390</td>\n",
       "      <td>0.8846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.262227</td>\n",
       "      <td>0.904673</td>\n",
       "      <td>0.317986</td>\n",
       "      <td>0.8870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.257125</td>\n",
       "      <td>0.907727</td>\n",
       "      <td>0.326534</td>\n",
       "      <td>0.8860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.252312</td>\n",
       "      <td>0.908909</td>\n",
       "      <td>0.301352</td>\n",
       "      <td>0.8926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.247960</td>\n",
       "      <td>0.910273</td>\n",
       "      <td>0.312819</td>\n",
       "      <td>0.8860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.244790</td>\n",
       "      <td>0.911564</td>\n",
       "      <td>0.294247</td>\n",
       "      <td>0.8934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.239608</td>\n",
       "      <td>0.913945</td>\n",
       "      <td>0.318711</td>\n",
       "      <td>0.8788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.236772</td>\n",
       "      <td>0.914709</td>\n",
       "      <td>0.294561</td>\n",
       "      <td>0.8942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.231362</td>\n",
       "      <td>0.916164</td>\n",
       "      <td>0.300827</td>\n",
       "      <td>0.8918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.228610</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.296085</td>\n",
       "      <td>0.8948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   0.715961  0.761873  0.509121        0.8234\n",
       "1   0.489252  0.829236  0.441950        0.8512\n",
       "2   0.444401  0.843200  0.409725        0.8596\n",
       "3   0.417573  0.852909  0.399407        0.8620\n",
       "4   0.397692  0.860891  0.377473        0.8722\n",
       "5   0.381477  0.866400  0.383061        0.8646\n",
       "6   0.367873  0.868709  0.360080        0.8722\n",
       "7   0.356671  0.872909  0.352227        0.8776\n",
       "8   0.345943  0.875927  0.350135        0.8728\n",
       "9   0.335326  0.879745  0.349719        0.8768\n",
       "10  0.327220  0.883600  0.343063        0.8780\n",
       "11  0.319549  0.885345  0.339544        0.8806\n",
       "12  0.312339  0.888782  0.340266        0.8794\n",
       "13  0.305344  0.890000  0.330250        0.8824\n",
       "14  0.298564  0.891836  0.327683        0.8832\n",
       "15  0.293506  0.893545  0.314891        0.8844\n",
       "16  0.285950  0.896309  0.315100        0.8864\n",
       "17  0.280920  0.899236  0.315711        0.8848\n",
       "18  0.275325  0.900582  0.313819        0.8850\n",
       "19  0.270304  0.902182  0.308889        0.8876\n",
       "20  0.265079  0.903691  0.318390        0.8846\n",
       "21  0.262227  0.904673  0.317986        0.8870\n",
       "22  0.257125  0.907727  0.326534        0.8860\n",
       "23  0.252312  0.908909  0.301352        0.8926\n",
       "24  0.247960  0.910273  0.312819        0.8860\n",
       "25  0.244790  0.911564  0.294247        0.8934\n",
       "26  0.239608  0.913945  0.318711        0.8788\n",
       "27  0.236772  0.914709  0.294561        0.8942\n",
       "28  0.231362  0.916164  0.300827        0.8918\n",
       "29  0.228610  0.917582  0.296085        0.8948"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 시각화\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 673us/step - loss: 0.3309 - accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3308800458908081, 0.883400022983551]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터셋 평가\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련된 모델을 사용해 예측\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "[9 2 1]\n",
      "['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "# 훈련된 모델을 사용해 예측, 이때는 결과값으로 가장 높은 확률의 class가 나온다\n",
    "import numpy as np\n",
    "\n",
    "# y_pred = model.predict_classes(X_new) tensorflow 버전 2.6이후로 사라짐\n",
    "y_pred = np.argmax(model.predict(X_new), axis = 1)\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target) # size를 지정하지않으몀 75대 25비율로 나뉘어진다\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.9461 - val_loss: 1.1949\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.6110 - val_loss: 0.4818\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 669us/step - loss: 0.4938 - val_loss: 0.5194\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.4662 - val_loss: 0.5695\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.4539 - val_loss: 0.6433\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.4438 - val_loss: 0.7235\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.4378 - val_loss: 0.8551\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 675us/step - loss: 0.4320 - val_loss: 0.9200\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.4267 - val_loss: 1.0373\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 683us/step - loss: 0.4247 - val_loss: 1.1728\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.4202 - val_loss: 1.2852\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 688us/step - loss: 0.4174 - val_loss: 1.4553\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.4122 - val_loss: 1.6149\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.4096 - val_loss: 1.7296\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.4061 - val_loss: 1.9583\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 720us/step - loss: 0.4021 - val_loss: 2.0911\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.3988 - val_loss: 2.2217\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.3988 - val_loss: 2.6775\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.3950 - val_loss: 2.6212\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.3927 - val_loss: 2.9168\n",
      "162/162 [==============================] - 0s 531us/step - loss: 3.6747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.674673080444336"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에 잡음이 많아서 과대적합을 막는 용도로 뉴런 수가 적은 은닉층 하나만 사용\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.355779340915301"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "np.mean((y_pred[:3] - y_test[:3])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 함수형 API를 이용해 복잡한 모델 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.8966 - val_loss: 2.2483\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 638us/step - loss: 4.6894 - val_loss: 0.9698\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 766us/step - loss: 0.5328 - val_loss: 0.7855\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.4934 - val_loss: 0.6850\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.4590 - val_loss: 0.5930\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 647us/step - loss: 0.4287 - val_loss: 0.5707\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 640us/step - loss: 0.4169 - val_loss: 0.6111\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 656us/step - loss: 0.4015 - val_loss: 0.6170\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.3854 - val_loss: 0.6854\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.3831 - val_loss: 0.7104\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 639us/step - loss: 0.3718 - val_loss: 0.8570\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 650us/step - loss: 0.3682 - val_loss: 0.8190\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 656us/step - loss: 0.3652 - val_loss: 0.8726\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.3613 - val_loss: 0.9269\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 654us/step - loss: 0.3481 - val_loss: 1.0007\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 652us/step - loss: 0.3519 - val_loss: 1.0405\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.3406 - val_loss: 1.3069\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 651us/step - loss: 0.3399 - val_loss: 1.1163\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 645us/step - loss: 0.3406 - val_loss: 1.1514\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 750us/step - loss: 0.3325 - val_loss: 1.2558\n",
      "162/162 [==============================] - 0s 495us/step - loss: 1.2970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2970129251480103"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_], outputs=[output])\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape = [5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape = [6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 889us/step - loss: 2.3793 - val_loss: 0.8763\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 683us/step - loss: 0.8403 - val_loss: 0.6613\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 686us/step - loss: 0.7121 - val_loss: 0.5975\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 689us/step - loss: 0.6618 - val_loss: 0.5636\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.6314 - val_loss: 0.5344\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.6082 - val_loss: 0.5147\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 684us/step - loss: 0.5889 - val_loss: 0.4945\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.5724 - val_loss: 0.4805\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.5583 - val_loss: 0.4709\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.5462 - val_loss: 0.4609\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 683us/step - loss: 0.5359 - val_loss: 0.4509\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.5273 - val_loss: 0.4474\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 734us/step - loss: 0.5195 - val_loss: 0.4415\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.5136 - val_loss: 0.4433\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.5077 - val_loss: 0.4399\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 676us/step - loss: 0.5040 - val_loss: 0.4412\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 678us/step - loss: 0.4998 - val_loss: 0.4428\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 674us/step - loss: 0.4965 - val_loss: 0.4388\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.4932 - val_loss: 0.4434\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.4903 - val_loss: 0.4487\n",
      "162/162 [==============================] - 0s 509us/step - loss: 0.4630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46298715472221375"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'mse', optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data = ((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보조출력 추가 \n",
    "\n",
    "input_A = keras.layers.Input(shape = [5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape = [6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name = 'main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2) # 보조 출력\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보조출력을 추가한 모델 컴파일 방법\n",
    "\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd') # 주출력의 가중치를 0.9, 보조출력의 가중치를 0.1로 두어서 주출력 위주로 모델을 훈련하도록 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1915 - main_output_loss: 1.0542 - aux_output_loss: 2.4271 - val_loss: 0.5895 - val_main_output_loss: 0.5206 - val_aux_output_loss: 1.2100\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.6411 - main_output_loss: 0.5815 - aux_output_loss: 1.1772 - val_loss: 0.5893 - val_main_output_loss: 0.5492 - val_aux_output_loss: 0.9503\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.5482 - main_output_loss: 0.5015 - aux_output_loss: 0.9690 - val_loss: 0.6561 - val_main_output_loss: 0.6354 - val_aux_output_loss: 0.8425\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.5122 - main_output_loss: 0.4757 - aux_output_loss: 0.8407 - val_loss: 0.7278 - val_main_output_loss: 0.7189 - val_aux_output_loss: 0.8084\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.4894 - main_output_loss: 0.4586 - aux_output_loss: 0.7661 - val_loss: 0.7824 - val_main_output_loss: 0.7777 - val_aux_output_loss: 0.8250\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.4733 - main_output_loss: 0.4473 - aux_output_loss: 0.7075 - val_loss: 0.9654 - val_main_output_loss: 0.9722 - val_aux_output_loss: 0.9047\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.4634 - main_output_loss: 0.4400 - aux_output_loss: 0.6743 - val_loss: 1.1701 - val_main_output_loss: 1.1871 - val_aux_output_loss: 1.0173\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.4505 - main_output_loss: 0.4284 - aux_output_loss: 0.6489 - val_loss: 1.3215 - val_main_output_loss: 1.3456 - val_aux_output_loss: 1.1045\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.4419 - main_output_loss: 0.4214 - aux_output_loss: 0.6270 - val_loss: 1.5253 - val_main_output_loss: 1.5607 - val_aux_output_loss: 1.2063\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.4293 - main_output_loss: 0.4095 - aux_output_loss: 0.6080 - val_loss: 1.9023 - val_main_output_loss: 1.9560 - val_aux_output_loss: 1.4185\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.4248 - main_output_loss: 0.4060 - aux_output_loss: 0.5935 - val_loss: 1.8352 - val_main_output_loss: 1.8816 - val_aux_output_loss: 1.4180\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.4187 - main_output_loss: 0.4007 - aux_output_loss: 0.5807 - val_loss: 2.0631 - val_main_output_loss: 2.1174 - val_aux_output_loss: 1.5748\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 741us/step - loss: 0.4112 - main_output_loss: 0.3944 - aux_output_loss: 0.5620 - val_loss: 2.4650 - val_main_output_loss: 2.5402 - val_aux_output_loss: 1.7882\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 755us/step - loss: 0.4007 - main_output_loss: 0.3843 - aux_output_loss: 0.5488 - val_loss: 2.8024 - val_main_output_loss: 2.8913 - val_aux_output_loss: 2.0025\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.3979 - main_output_loss: 0.3825 - aux_output_loss: 0.5367 - val_loss: 3.2115 - val_main_output_loss: 3.3148 - val_aux_output_loss: 2.2810\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 783us/step - loss: 0.3915 - main_output_loss: 0.3766 - aux_output_loss: 0.5255 - val_loss: 3.2054 - val_main_output_loss: 3.3044 - val_aux_output_loss: 2.3143\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3851 - main_output_loss: 0.3705 - aux_output_loss: 0.5170 - val_loss: 3.4025 - val_main_output_loss: 3.5048 - val_aux_output_loss: 2.4822\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 751us/step - loss: 0.3827 - main_output_loss: 0.3685 - aux_output_loss: 0.5103 - val_loss: 4.0688 - val_main_output_loss: 4.2016 - val_aux_output_loss: 2.8733\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.3792 - main_output_loss: 0.3654 - aux_output_loss: 0.5027 - val_loss: 3.8920 - val_main_output_loss: 4.0077 - val_aux_output_loss: 2.8510\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 747us/step - loss: 0.3757 - main_output_loss: 0.3625 - aux_output_loss: 0.4951 - val_loss: 4.6315 - val_main_output_loss: 4.7823 - val_aux_output_loss: 3.2743\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train], epochs = 20,\n",
    "    validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 654us/step - loss: 5.5557 - main_output_loss: 5.7412 - aux_output_loss: 3.8868\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 서브클래싱 API로 동적 모델 만들기 \n",
    "\n",
    "* 시퀀셜 API와 함수형 API는 모두 선언적, 사용할 층과 연결 방식을 먼저 정의해야함\n",
    "* 모델에 반복문을 추가할수도 있고 다양한 크기를 다루려면 서브클래싱 API를 사용해야함\n",
    "\n",
    "한계\n",
    "* 모델을 저장하거나 복사할 수 없다\n",
    "* summary() 메서드를 호출하면 층의 목록만 나열되고 층 간의 연결 정보를 얻을 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units = 30, activation = 'relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 저장과 복원\n",
    "\n",
    "```python\n",
    "# model save\n",
    "model = keras.models.Sequential([...])\n",
    "model.compile([...])\n",
    "model.fit([...])\n",
    "model.save(\"my_keras_model.h5\")\n",
    "\n",
    "# model load\n",
    "model = keras.models.load_model('my_keras_model.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 콜백 사용하기\n",
    "\n",
    "* fit() 메서드의 callbacks 매개변수를 사용하여 케라스가 훈련의 시작이나 끝에 호출할 객체 리스트를 저장 가능\n",
    "* 예를들어 ModelCheckppoint는 훈련하는 동안 일정한 간격으로 모델의 체크포인트를 저장, 기본적으로 매 에포크의 끝에서 호출\n",
    "\n",
    "```python \n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5')\n",
    "history = model.fit(X_train, y_train, epochs = 10, callbacks=[checkpoint_cb])\n",
    "\n",
    "# 최상 결과(검증세트에서, 따라서 validation_data 지정이 필요)만 저장\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only = True)\n",
    "history = model.fit(X_train, y_train, epochs = 10, \n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model('my_keras_model.h5')\n",
    "\n",
    "# 모델의 개선이 없을경우 조기 종료\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history = model.fit(X_train, y_train, epochs = 100,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    callbacks = [checkpoint_cb, early_stopping_cb])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_keras_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_cb])\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3983\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3978\u001b[0m     \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3980\u001b[0m     \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[1;32m   3981\u001b[0m     \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3982\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   3984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3985\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3987\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. RNN과 CNN을 사용해 시퀀스 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3 시계열 예측하기\n",
    "\n",
    "p.604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터 생성 함수\n",
    "import numpy as np\n",
    "\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_stpes 이 50개인 데이터 10000개\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.1 기준 성능\n",
    "\n",
    "* naive forecast 보다 좋아야지 모델을 사용하는 의미가 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020081257"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "# 마지막값을 \n",
    "\n",
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 0s 470us/step - loss: 0.1074\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 527us/step - loss: 0.0401\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 312us/step - loss: 0.0241\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 308us/step - loss: 0.0178\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 303us/step - loss: 0.0145\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 313us/step - loss: 0.0123\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 312us/step - loss: 0.0105\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 306us/step - loss: 0.0091\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 307us/step - loss: 0.0079\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 307us/step - loss: 0.0070\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 305us/step - loss: 0.0062\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 300us/step - loss: 0.0056\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 313us/step - loss: 0.0052\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 343us/step - loss: 0.0048\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 334us/step - loss: 0.0046\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 307us/step - loss: 0.0044\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 309us/step - loss: 0.0042\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 315us/step - loss: 0.0041\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 311us/step - loss: 0.0040\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 315us/step - loss: 0.0039\n",
      "63/63 [==============================] - 0s 279us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0040120278"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 완전 연결 네트워크를 사용한 예측\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [50,1]), # flatten 계층이 없으면 y_pred는 (2000, 50, 1)로 출력됨\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='Adam', loss = 'mse')\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.2 간단한 RNN 구현하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1435\n",
      "63/63 [==============================] - 0s 744us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14080665"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape = [None, 1])\n",
    "])\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.3 심층 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0336\n",
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.008754198"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]), # 각 시점에서 결과값이 20개가 나온다\n",
    "    keras.layers.SimpleRNN(20, return_sequences= True), # 각 시점에서 결과값이 20개 \n",
    "    keras.layers.SimpleRNN(1), # 마지막 층에서는 return_sequences를 정의할 필요 없다\n",
    "])\n",
    "model.compile(optimizer='Adam', loss = 'mse')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 50, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 5ms/step - loss: 0.0093\n",
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0040185642"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]), # 각 시점에서 결과값이 20개가 나온다\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(optimizer='Adam', loss = 'mse')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 50, 20)\n",
      "(7000, 20)\n",
      "(7000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 직접 실행하며 어떤식으로 연산이 되는지 확인\n",
    "\n",
    "rnn1 = keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1])\n",
    "hidden_state1 = rnn1(X_train)\n",
    "print(hidden_state1.shape)\n",
    "\n",
    "rnn2 = keras.layers.SimpleRNN(20)\n",
    "hidden_state2 = rnn2(hidden_state1)\n",
    "print(hidden_state2.shape)\n",
    "\n",
    "dense1 = keras.layers.Dense(1)\n",
    "res = dense1(hidden_state2)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.3 여러 타임 스텝 앞을 예측하기\n",
    "\n",
    "* 첫번째 방법 : 이미 훈련된 모델을 사용하여 다음값을 예측한 다음 이 값을 입력으로 추가하여 새롭게 그 다음값을 예측\n",
    "* 두번째 방법 : RNN을 훈련하여 다음 값 10개를 한 번에 예측하는것, 시퀀스-투-벡터 모델을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.042548746"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 방법\n",
    "n_steps = 50\n",
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    \n",
    "Y_pred = X[:, n_steps:]\n",
    "np.mean(keras.losses.mse(Y_new, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 방법\n",
    "\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "series.shape\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0] # series[:7000, -10:, 0] : (7000, 10) series[:7000, -10:] : (7000, 10, 1 )\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 데이터 생성\n",
    "\n",
    "Y = np.empty((10000, n_steps, 10))\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :, step_ahead -1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
    "\n",
    "Y_train = Y[:7000] \n",
    "Y_valid = Y[7000:9000]\n",
    "Y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 5ms/step - loss: 0.0671 - last_time_step_mse: 0.0676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1776e1d50>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))    \n",
    "])\n",
    "\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse', metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 50, 10)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
