{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2부 신경망과 딥러닝\n",
    "\n",
    "p.350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 케라스를 사용한 인공 신경망 소개\n",
    "\n",
    "p.351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 케라스로 다층 퍼셉트론 구현하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 텐서플로우 설치\n",
    "\n",
    "* 설치 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 시퀀셜 API를 사용하여 이미지 분류기 만들기 \n",
    "\n",
    "* 패션 MNIST 데이터 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 스케일링\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train은 숫자 라벨, 정확한 라벨 지정이 필요\n",
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : 하이퍼 파라미터 갯수\n",
    "\n",
    "* 입력데이터가 28 * 28 사이즈\n",
    "* 은닉층이 300 사이즈\n",
    "* 가중치 300개\n",
    "* 따라서 최종 파라미터는 ```28 * 28 * 300 + 300```\n",
    "* 가중치 파라미터가 있다는걸 생각해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성, 두 개의 은닉층으로 이루어진 분류용 다층 퍼셉트론\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.layers.reshaping.flatten.Flatten at 0x2c50bb010>,\n",
       " <keras.src.layers.core.dense.Dense at 0x2c50fa910>,\n",
       " <keras.src.layers.core.dense.Dense at 0x2c43ba350>,\n",
       " <keras.src.layers.core.dense.Dense at 0x2c5149650>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02261573 -0.00483678  0.06030057 ...  0.05531289  0.01990859\n",
      "  -0.0539845 ]\n",
      " [-0.02860873  0.01165161  0.03260668 ... -0.04193401 -0.07387442\n",
      "   0.05382681]\n",
      " [-0.06730554  0.03318278  0.00536086 ... -0.05477669 -0.07336121\n",
      "  -0.02859459]\n",
      " ...\n",
      " [ 0.01604614 -0.05070014 -0.01977684 ...  0.0299964  -0.05279319\n",
      "  -0.06868849]\n",
      " [ 0.02835996 -0.06097573 -0.01141511 ... -0.07334358 -0.05264599\n",
      "   0.01435699]\n",
      " [ 0.03206318 -0.03784311  0.0461437  ...  0.06474936 -0.01378744\n",
      "   0.05318072]]\n",
      "(784, 300)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights() # 첫번째 은닉층의 초기 가중치, 편향\n",
    "print(weights)\n",
    "print(weights.shape)\n",
    "print(biases)\n",
    "print(biases.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'sgd',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : sparse_categorical_crossentropy와 categorical_crossentropy의 차이점\n",
    "\n",
    "* 샘플마다 타겟 클레스가 하나 이면(예를들어 1번샘플의 정답 = 9, 2번샘플의 정답 = 3) sparse ~ 사용\n",
    "* 샘플마다 타겟 클래스가 원핫 인코딩 벡터형태면(1번 샘플의 정답 = (0,1,0,0), 2번 샘플의 정답 = (1,0,0,0)) categorical ~ 사용\n",
    "    * 원 핫 벡터 변환 함수 : keras.utils.to_categorical()\n",
    "    * 반대는 np.argmax(axis = 1)를 이용해 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer = sgd는 경사 하강법을 이용해 훈련 한다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics = ['accuracy']는 분류 문제이기 때문에 이러한 형태로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : model.fit() 메서드 \n",
    "\n",
    "* fit() 메서드는 마지막으로 실행한 파라미터 값을 기억한다, 따라서 다시 실행하게 되면 마지막에 최적화된 파라미터에서 시작함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 1s 794us/step - loss: 0.7104 - accuracy: 0.7650 - val_loss: 0.5401 - val_accuracy: 0.8186\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 1s 722us/step - loss: 0.4862 - accuracy: 0.8302 - val_loss: 0.4393 - val_accuracy: 0.8528\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 1s 725us/step - loss: 0.4412 - accuracy: 0.8457 - val_loss: 0.4278 - val_accuracy: 0.8520\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 1s 703us/step - loss: 0.4132 - accuracy: 0.8544 - val_loss: 0.3998 - val_accuracy: 0.8596\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 1s 704us/step - loss: 0.3941 - accuracy: 0.8618 - val_loss: 0.4285 - val_accuracy: 0.8460\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 1s 724us/step - loss: 0.3775 - accuracy: 0.8667 - val_loss: 0.3619 - val_accuracy: 0.8718\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 1s 704us/step - loss: 0.3649 - accuracy: 0.8708 - val_loss: 0.3888 - val_accuracy: 0.8648\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 1s 710us/step - loss: 0.3527 - accuracy: 0.8749 - val_loss: 0.3645 - val_accuracy: 0.8744\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 1s 717us/step - loss: 0.3412 - accuracy: 0.8796 - val_loss: 0.3508 - val_accuracy: 0.8748\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 1s 705us/step - loss: 0.3322 - accuracy: 0.8802 - val_loss: 0.3537 - val_accuracy: 0.8760\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 1s 717us/step - loss: 0.3243 - accuracy: 0.8835 - val_loss: 0.3369 - val_accuracy: 0.8822\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 1s 713us/step - loss: 0.3160 - accuracy: 0.8861 - val_loss: 0.3347 - val_accuracy: 0.8848\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 1s 711us/step - loss: 0.3086 - accuracy: 0.8884 - val_loss: 0.3264 - val_accuracy: 0.8866\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 1s 720us/step - loss: 0.3021 - accuracy: 0.8912 - val_loss: 0.3393 - val_accuracy: 0.8770\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 1s 718us/step - loss: 0.2948 - accuracy: 0.8935 - val_loss: 0.3263 - val_accuracy: 0.8816\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 1s 728us/step - loss: 0.2892 - accuracy: 0.8955 - val_loss: 0.3306 - val_accuracy: 0.8832\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 1s 732us/step - loss: 0.2832 - accuracy: 0.8972 - val_loss: 0.3141 - val_accuracy: 0.8864\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 1s 726us/step - loss: 0.2781 - accuracy: 0.8991 - val_loss: 0.3130 - val_accuracy: 0.8892\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 1s 714us/step - loss: 0.2724 - accuracy: 0.9019 - val_loss: 0.3281 - val_accuracy: 0.8782\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 1s 719us/step - loss: 0.2675 - accuracy: 0.9029 - val_loss: 0.3269 - val_accuracy: 0.8808\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 1s 720us/step - loss: 0.2626 - accuracy: 0.9053 - val_loss: 0.3067 - val_accuracy: 0.8898\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 1s 714us/step - loss: 0.2582 - accuracy: 0.9068 - val_loss: 0.3057 - val_accuracy: 0.8926\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 1s 720us/step - loss: 0.2534 - accuracy: 0.9091 - val_loss: 0.3031 - val_accuracy: 0.8916\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 1s 717us/step - loss: 0.2489 - accuracy: 0.9107 - val_loss: 0.3093 - val_accuracy: 0.8910\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 1s 723us/step - loss: 0.2455 - accuracy: 0.9116 - val_loss: 0.3087 - val_accuracy: 0.8904\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 1s 720us/step - loss: 0.2406 - accuracy: 0.9130 - val_loss: 0.2965 - val_accuracy: 0.8970\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 1s 722us/step - loss: 0.2368 - accuracy: 0.9145 - val_loss: 0.2987 - val_accuracy: 0.8964\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 1s 736us/step - loss: 0.2340 - accuracy: 0.9159 - val_loss: 0.3114 - val_accuracy: 0.8838\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 1s 723us/step - loss: 0.2294 - accuracy: 0.9171 - val_loss: 0.2950 - val_accuracy: 0.8912\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 1s 718us/step - loss: 0.2248 - accuracy: 0.9190 - val_loss: 0.2878 - val_accuracy: 0.8974\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련과 평가\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 분포가 편중되어있다면 fit()메서드를 호출할때 class_weight 매개변수를 지정할 수 잇다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710417</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.540105</td>\n",
       "      <td>0.8186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.486248</td>\n",
       "      <td>0.830182</td>\n",
       "      <td>0.439281</td>\n",
       "      <td>0.8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.441207</td>\n",
       "      <td>0.845709</td>\n",
       "      <td>0.427818</td>\n",
       "      <td>0.8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.413176</td>\n",
       "      <td>0.854400</td>\n",
       "      <td>0.399828</td>\n",
       "      <td>0.8596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.394144</td>\n",
       "      <td>0.861818</td>\n",
       "      <td>0.428495</td>\n",
       "      <td>0.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.377473</td>\n",
       "      <td>0.866655</td>\n",
       "      <td>0.361879</td>\n",
       "      <td>0.8718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.364878</td>\n",
       "      <td>0.870764</td>\n",
       "      <td>0.388803</td>\n",
       "      <td>0.8648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.352653</td>\n",
       "      <td>0.874927</td>\n",
       "      <td>0.364463</td>\n",
       "      <td>0.8744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.341171</td>\n",
       "      <td>0.879618</td>\n",
       "      <td>0.350784</td>\n",
       "      <td>0.8748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.332204</td>\n",
       "      <td>0.880164</td>\n",
       "      <td>0.353715</td>\n",
       "      <td>0.8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.324261</td>\n",
       "      <td>0.883473</td>\n",
       "      <td>0.336862</td>\n",
       "      <td>0.8822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.316016</td>\n",
       "      <td>0.886145</td>\n",
       "      <td>0.334726</td>\n",
       "      <td>0.8848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.308568</td>\n",
       "      <td>0.888400</td>\n",
       "      <td>0.326415</td>\n",
       "      <td>0.8866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.302059</td>\n",
       "      <td>0.891182</td>\n",
       "      <td>0.339254</td>\n",
       "      <td>0.8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.294808</td>\n",
       "      <td>0.893491</td>\n",
       "      <td>0.326343</td>\n",
       "      <td>0.8816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.289168</td>\n",
       "      <td>0.895455</td>\n",
       "      <td>0.330595</td>\n",
       "      <td>0.8832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.283187</td>\n",
       "      <td>0.897182</td>\n",
       "      <td>0.314065</td>\n",
       "      <td>0.8864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.278109</td>\n",
       "      <td>0.899055</td>\n",
       "      <td>0.313029</td>\n",
       "      <td>0.8892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.272352</td>\n",
       "      <td>0.901891</td>\n",
       "      <td>0.328132</td>\n",
       "      <td>0.8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.267468</td>\n",
       "      <td>0.902945</td>\n",
       "      <td>0.326875</td>\n",
       "      <td>0.8808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.262563</td>\n",
       "      <td>0.905345</td>\n",
       "      <td>0.306653</td>\n",
       "      <td>0.8898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.258154</td>\n",
       "      <td>0.906800</td>\n",
       "      <td>0.305654</td>\n",
       "      <td>0.8926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.253430</td>\n",
       "      <td>0.909073</td>\n",
       "      <td>0.303126</td>\n",
       "      <td>0.8916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.248914</td>\n",
       "      <td>0.910673</td>\n",
       "      <td>0.309283</td>\n",
       "      <td>0.8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.245483</td>\n",
       "      <td>0.911582</td>\n",
       "      <td>0.308741</td>\n",
       "      <td>0.8904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.240631</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.296465</td>\n",
       "      <td>0.8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.236809</td>\n",
       "      <td>0.914509</td>\n",
       "      <td>0.298750</td>\n",
       "      <td>0.8964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.233982</td>\n",
       "      <td>0.915891</td>\n",
       "      <td>0.311371</td>\n",
       "      <td>0.8838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.229425</td>\n",
       "      <td>0.917073</td>\n",
       "      <td>0.295038</td>\n",
       "      <td>0.8912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.224780</td>\n",
       "      <td>0.919018</td>\n",
       "      <td>0.287764</td>\n",
       "      <td>0.8974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   0.710417  0.764964  0.540105        0.8186\n",
       "1   0.486248  0.830182  0.439281        0.8528\n",
       "2   0.441207  0.845709  0.427818        0.8520\n",
       "3   0.413176  0.854400  0.399828        0.8596\n",
       "4   0.394144  0.861818  0.428495        0.8460\n",
       "5   0.377473  0.866655  0.361879        0.8718\n",
       "6   0.364878  0.870764  0.388803        0.8648\n",
       "7   0.352653  0.874927  0.364463        0.8744\n",
       "8   0.341171  0.879618  0.350784        0.8748\n",
       "9   0.332204  0.880164  0.353715        0.8760\n",
       "10  0.324261  0.883473  0.336862        0.8822\n",
       "11  0.316016  0.886145  0.334726        0.8848\n",
       "12  0.308568  0.888400  0.326415        0.8866\n",
       "13  0.302059  0.891182  0.339254        0.8770\n",
       "14  0.294808  0.893491  0.326343        0.8816\n",
       "15  0.289168  0.895455  0.330595        0.8832\n",
       "16  0.283187  0.897182  0.314065        0.8864\n",
       "17  0.278109  0.899055  0.313029        0.8892\n",
       "18  0.272352  0.901891  0.328132        0.8782\n",
       "19  0.267468  0.902945  0.326875        0.8808\n",
       "20  0.262563  0.905345  0.306653        0.8898\n",
       "21  0.258154  0.906800  0.305654        0.8926\n",
       "22  0.253430  0.909073  0.303126        0.8916\n",
       "23  0.248914  0.910673  0.309283        0.8910\n",
       "24  0.245483  0.911582  0.308741        0.8904\n",
       "25  0.240631  0.913018  0.296465        0.8970\n",
       "26  0.236809  0.914509  0.298750        0.8964\n",
       "27  0.233982  0.915891  0.311371        0.8838\n",
       "28  0.229425  0.917073  0.295038        0.8912\n",
       "29  0.224780  0.919018  0.287764        0.8974"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 시각화\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 478us/step - loss: 0.3236 - accuracy: 0.8806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32363757491111755, 0.8805999755859375]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터셋 평가\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련된 모델을 사용해 예측\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "[9 2 1]\n",
      "['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "# 훈련된 모델을 사용해 예측, 이때는 결과값으로 가장 높은 확률의 class가 나온다\n",
    "import numpy as np\n",
    "\n",
    "# y_pred = model.predict_classes(X_new) tensorflow 버전 2.6이후로 사라짐\n",
    "y_pred = np.argmax(model.predict(X_new), axis = 1)\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target) # size를 지정하지않으몀 75대 25비율로 나뉘어진다\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 493us/step - loss: 1.2612 - val_loss: 0.5707\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 371us/step - loss: 0.5135 - val_loss: 0.4927\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 372us/step - loss: 0.4669 - val_loss: 0.4552\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 383us/step - loss: 0.4501 - val_loss: 0.4422\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 374us/step - loss: 0.4340 - val_loss: 0.4234\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.4213 - val_loss: 0.4167\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 369us/step - loss: 0.4124 - val_loss: 0.4133\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 370us/step - loss: 0.4052 - val_loss: 0.4076\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.4003 - val_loss: 0.5186\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 369us/step - loss: 0.3974 - val_loss: 0.4093\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 367us/step - loss: 0.3919 - val_loss: 0.4105\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 369us/step - loss: 0.3856 - val_loss: 0.4054\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.3830 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 365us/step - loss: 0.3779 - val_loss: 0.4146\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.3762 - val_loss: 0.4220\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 367us/step - loss: 0.3735 - val_loss: 0.4216\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 367us/step - loss: 0.3711 - val_loss: 0.4581\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 370us/step - loss: 0.3691 - val_loss: 0.4243\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 362us/step - loss: 0.3693 - val_loss: 0.4360\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 366us/step - loss: 0.3627 - val_loss: 0.4512\n",
      "162/162 [==============================] - 0s 248us/step - loss: 3.3041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.304077386856079"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에 잡음이 많아서 과대적합을 막는 용도로 뉴런 수가 적은 은닉층 하나만 사용\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.310539179674484"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "np.mean((y_pred[:3] - y_test[:3])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 함수형 API를 이용해 복잡한 모델 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 547us/step - loss: 4.1712 - val_loss: 852.1473\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 352us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 350us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 347us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 349us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 352us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 349us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 347us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 345us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 349us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 348us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 348us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 349us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 375us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 367us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 345us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 348us/step - loss: nan - val_loss: nan\n",
      "162/162 [==============================] - 0s 246us/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_], outputs=[output])\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape = [5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape = [6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 513us/step - loss: 2.3100 - val_loss: 1.0370\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 371us/step - loss: 0.8362 - val_loss: 0.7301\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 369us/step - loss: 0.6806 - val_loss: 0.6425\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 366us/step - loss: 0.6199 - val_loss: 0.5978\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 373us/step - loss: 0.5839 - val_loss: 0.5664\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 358us/step - loss: 0.5575 - val_loss: 0.5459\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 371us/step - loss: 0.5375 - val_loss: 0.5259\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 364us/step - loss: 0.5214 - val_loss: 0.5123\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 363us/step - loss: 0.5083 - val_loss: 0.4998\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 0.4980 - val_loss: 0.4891\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 359us/step - loss: 0.4900 - val_loss: 0.4848\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 365us/step - loss: 0.4837 - val_loss: 0.4767\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 370us/step - loss: 0.4781 - val_loss: 0.4701\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 368us/step - loss: 0.4741 - val_loss: 0.4662\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 362us/step - loss: 0.4710 - val_loss: 0.4634\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 362us/step - loss: 0.4678 - val_loss: 0.4602\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 363us/step - loss: 0.4646 - val_loss: 0.4573\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 370us/step - loss: 0.4633 - val_loss: 0.4560\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 365us/step - loss: 0.4608 - val_loss: 0.4555\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 0.4587 - val_loss: 0.4532\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.7451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.745054304599762"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'mse', optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data = ((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보조출력 추가 \n",
    "\n",
    "input_A = keras.layers.Input(shape = [5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape = [6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name = 'main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2) # 보조 출력\n",
    "model = keras.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보조출력을 추가한 모델 컴파일 방법\n",
    "\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd') # 주출력의 가중치를 0.9, 보조출력의 가중치를 0.1로 두어서 주출력 위주로 모델을 훈련하도록 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 624us/step - loss: 0.9528 - main_output_loss: 0.8263 - aux_output_loss: 2.0916 - val_loss: 0.6304 - val_main_output_loss: 0.5624 - val_aux_output_loss: 1.2416\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 423us/step - loss: 0.5452 - main_output_loss: 0.4824 - aux_output_loss: 1.1107 - val_loss: 0.5195 - val_main_output_loss: 0.4617 - val_aux_output_loss: 1.0404\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 417us/step - loss: 0.5143 - main_output_loss: 0.4644 - aux_output_loss: 0.9636 - val_loss: 0.4925 - val_main_output_loss: 0.4470 - val_aux_output_loss: 0.9022\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.5025 - main_output_loss: 0.4622 - aux_output_loss: 0.8651 - val_loss: 0.4843 - val_main_output_loss: 0.4447 - val_aux_output_loss: 0.8402\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 417us/step - loss: 0.4833 - main_output_loss: 0.4479 - aux_output_loss: 0.8025 - val_loss: 0.5059 - val_main_output_loss: 0.4778 - val_aux_output_loss: 0.7589\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.4664 - main_output_loss: 0.4366 - aux_output_loss: 0.7348 - val_loss: 0.4637 - val_main_output_loss: 0.4372 - val_aux_output_loss: 0.7018\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.4787 - main_output_loss: 0.4538 - aux_output_loss: 0.7035 - val_loss: 0.4596 - val_main_output_loss: 0.4361 - val_aux_output_loss: 0.6707\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 417us/step - loss: 0.4482 - main_output_loss: 0.4246 - aux_output_loss: 0.6605 - val_loss: 0.4679 - val_main_output_loss: 0.4487 - val_aux_output_loss: 0.6408\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.4410 - main_output_loss: 0.4197 - aux_output_loss: 0.6328 - val_loss: 0.4621 - val_main_output_loss: 0.4443 - val_aux_output_loss: 0.6227\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.4320 - main_output_loss: 0.4117 - aux_output_loss: 0.6149 - val_loss: 0.4613 - val_main_output_loss: 0.4442 - val_aux_output_loss: 0.6154\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.4225 - main_output_loss: 0.4029 - aux_output_loss: 0.5990 - val_loss: 0.4722 - val_main_output_loss: 0.4563 - val_aux_output_loss: 0.6155\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.4161 - main_output_loss: 0.3971 - aux_output_loss: 0.5872 - val_loss: 0.4841 - val_main_output_loss: 0.4699 - val_aux_output_loss: 0.6121\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 427us/step - loss: 0.4095 - main_output_loss: 0.3910 - aux_output_loss: 0.5764 - val_loss: 0.5114 - val_main_output_loss: 0.4990 - val_aux_output_loss: 0.6227\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.4038 - main_output_loss: 0.3862 - aux_output_loss: 0.5620 - val_loss: 0.5127 - val_main_output_loss: 0.5016 - val_aux_output_loss: 0.6119\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 423us/step - loss: 0.4000 - main_output_loss: 0.3829 - aux_output_loss: 0.5543 - val_loss: 0.5408 - val_main_output_loss: 0.5314 - val_aux_output_loss: 0.6247\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 451us/step - loss: 0.3960 - main_output_loss: 0.3791 - aux_output_loss: 0.5477 - val_loss: 0.5743 - val_main_output_loss: 0.5678 - val_aux_output_loss: 0.6322\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.3906 - main_output_loss: 0.3741 - aux_output_loss: 0.5390 - val_loss: 0.5421 - val_main_output_loss: 0.5340 - val_aux_output_loss: 0.6156\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 423us/step - loss: 0.3837 - main_output_loss: 0.3677 - aux_output_loss: 0.5282 - val_loss: 0.5834 - val_main_output_loss: 0.5763 - val_aux_output_loss: 0.6469\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.3861 - main_output_loss: 0.3709 - aux_output_loss: 0.5234 - val_loss: 0.5844 - val_main_output_loss: 0.5768 - val_aux_output_loss: 0.6529\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 417us/step - loss: 0.3790 - main_output_loss: 0.3638 - aux_output_loss: 0.5151 - val_loss: 0.6206 - val_main_output_loss: 0.6152 - val_aux_output_loss: 0.6691\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train], epochs = 20,\n",
    "    validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 333us/step - loss: 5.6859 - main_output_loss: 5.7197 - aux_output_loss: 5.3818\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 서브클래싱 API로 동적 모델 만들기 \n",
    "\n",
    "* 시퀀셜 API와 함수형 API는 모두 선언적, 사용할 층과 연결 방식을 먼저 정의해야함\n",
    "* 모델에 반복문을 추가할수도 있고 다양한 크기를 다루려면 서브클래싱 API를 사용해야함\n",
    "\n",
    "한계\n",
    "* 모델을 저장하거나 복사할 수 없다\n",
    "* summary() 메서드를 호출하면 층의 목록만 나열되고 층 간의 연결 정보를 얻을 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units = 30, activation = 'relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 저장과 복원\n",
    "\n",
    "```python\n",
    "# model save\n",
    "model = keras.models.Sequential([...])\n",
    "model.compile([...])\n",
    "model.fit([...])\n",
    "model.save(\"my_keras_model.h5\")\n",
    "\n",
    "# model load\n",
    "model = keras.models.load_model('my_keras_model.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 콜백 사용하기\n",
    "\n",
    "* fit() 메서드의 callbacks 매개변수를 사용하여 케라스가 훈련의 시작이나 끝에 호출할 객체 리스트를 저장 가능\n",
    "* 예를들어 ModelCheckppoint는 훈련하는 동안 일정한 간격으로 모델의 체크포인트를 저장, 기본적으로 매 에포크의 끝에서 호출\n",
    "\n",
    "```python \n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5')\n",
    "history = model.fit(X_train, y_train, epochs = 10, callbacks=[checkpoint_cb])\n",
    "\n",
    "# 최상 결과(검증세트에서, 따라서 validation_data 지정이 필요)만 저장\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only = True)\n",
    "history = model.fit(X_train, y_train, epochs = 10, \n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model('my_keras_model.h5')\n",
    "\n",
    "# 모델의 개선이 없을경우 조기 종료\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "history = model.fit(X_train, y_train, epochs = 100,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    callbacks = [checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "# 사용자 정의 콜백 \n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\nval/train : {:.2f}'.format(logs['val_loss'] /  logs['loss']))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 텐서보드를 사용해 시각화하기 \n",
    "생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 신경망 하이퍼파라미터 튜닝하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden = 1, n_neurons = 30, lerangin_rate = 3e-3, input_shape=[8]):\n",
    "    model = keras.model.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lerangin_rate=lerangin_rate)\n",
    "    model.compile(loss = 'mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras' has no attribute 'wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrappers\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/study/lib/python3.11/site-packages/tensorflow/python/util/lazy_loader.py:59\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     58\u001b[0m   module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load()\n\u001b[0;32m---> 59\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras' has no attribute 'wrappers'"
     ]
    }
   ],
   "source": [
    "keras.wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. RNN과 CNN을 사용해 시퀀스 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3 시계열 예측하기\n",
    "\n",
    "p.604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터 생성 함수\n",
    "import numpy as np\n",
    "\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_stpes 이 50개인 데이터 10000개\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.1 기준 성능\n",
    "\n",
    "* naive forecast 보다 좋아야지 모델을 사용하는 의미가 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020081257"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "# 마지막값을 \n",
    "\n",
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 0s 470us/step - loss: 0.1074\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 527us/step - loss: 0.0401\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 312us/step - loss: 0.0241\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 308us/step - loss: 0.0178\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 303us/step - loss: 0.0145\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 313us/step - loss: 0.0123\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 312us/step - loss: 0.0105\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 306us/step - loss: 0.0091\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 307us/step - loss: 0.0079\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 307us/step - loss: 0.0070\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 305us/step - loss: 0.0062\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 300us/step - loss: 0.0056\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 313us/step - loss: 0.0052\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 343us/step - loss: 0.0048\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 334us/step - loss: 0.0046\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 307us/step - loss: 0.0044\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 309us/step - loss: 0.0042\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 315us/step - loss: 0.0041\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 311us/step - loss: 0.0040\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 315us/step - loss: 0.0039\n",
      "63/63 [==============================] - 0s 279us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0040120278"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 완전 연결 네트워크를 사용한 예측\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [50,1]), # flatten 계층이 없으면 y_pred는 (2000, 50, 1)로 출력됨\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='Adam', loss = 'mse')\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.2 간단한 RNN 구현하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1435\n",
      "63/63 [==============================] - 0s 744us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14080665"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape = [None, 1])\n",
    "])\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.3 심층 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0336\n",
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.008754198"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]), # 각 시점에서 결과값이 20개가 나온다\n",
    "    keras.layers.SimpleRNN(20, return_sequences= True), # 각 시점에서 결과값이 20개 \n",
    "    keras.layers.SimpleRNN(1), # 마지막 층에서는 return_sequences를 정의할 필요 없다\n",
    "])\n",
    "model.compile(optimizer='Adam', loss = 'mse')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 50, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 5ms/step - loss: 0.0093\n",
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0040185642"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]), # 각 시점에서 결과값이 20개가 나온다\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(optimizer='Adam', loss = 'mse')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 50, 20)\n",
      "(7000, 20)\n",
      "(7000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 직접 실행하며 어떤식으로 연산이 되는지 확인\n",
    "\n",
    "rnn1 = keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1])\n",
    "hidden_state1 = rnn1(X_train)\n",
    "print(hidden_state1.shape)\n",
    "\n",
    "rnn2 = keras.layers.SimpleRNN(20)\n",
    "hidden_state2 = rnn2(hidden_state1)\n",
    "print(hidden_state2.shape)\n",
    "\n",
    "dense1 = keras.layers.Dense(1)\n",
    "res = dense1(hidden_state2)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.3 여러 타임 스텝 앞을 예측하기\n",
    "\n",
    "* 첫번째 방법 : 이미 훈련된 모델을 사용하여 다음값을 예측한 다음 이 값을 입력으로 추가하여 새롭게 그 다음값을 예측\n",
    "* 두번째 방법 : RNN을 훈련하여 다음 값 10개를 한 번에 예측하는것, 시퀀스-투-벡터 모델을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.042548746"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 방법\n",
    "n_steps = 50\n",
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    \n",
    "Y_pred = X[:, n_steps:]\n",
    "np.mean(keras.losses.mse(Y_new, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 방법\n",
    "\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "series.shape\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0] # series[:7000, -10:, 0] : (7000, 10) series[:7000, -10:] : (7000, 10, 1 )\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 데이터 생성\n",
    "\n",
    "Y = np.empty((10000, n_steps, 10))\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :, step_ahead -1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
    "\n",
    "Y_train = Y[:7000] \n",
    "Y_valid = Y[7000:9000]\n",
    "Y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 5ms/step - loss: 0.0671 - last_time_step_mse: 0.0676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1776e1d50>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))    \n",
    "])\n",
    "\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse', metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 50, 10)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
